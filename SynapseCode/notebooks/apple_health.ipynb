{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python"
    },
    "save_output": true,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "%%pyspark\r\n",
        "activity = spark.read.load('datalake_path/ActiveEnergyBurned.csv', format='csv'\r\n",
        "## If header exists uncomment line below\r\n",
        ", header=True\r\n",
        ")\r\n",
        "display(df.limit(10))"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "StatementMeta(SparkPool01, 3, 1, Finished, Available)"
            ],
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "SparkPool01",
              "session_id": 3,
              "statement_id": 1,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-07-02T02:41:19.3335775Z",
              "session_start_time": "2021-07-02T02:41:19.3989752Z",
              "execution_start_time": "2021-07-02T02:44:20.5986541Z",
              "execution_finish_time": "2021-07-02T02:44:30.9805761Z"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df' is not defined",
          "traceback": [
            "NameError: name 'df' is not defined",
            "Traceback (most recent call last):\n",
            "NameError: name 'df' is not defined\n"
          ]
        }
      ],
      "metadata": {
        "microsoft": {
          "language": "python"
        },
        "collapsed": false
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "source": [
        "#view column data types\r\n",
        "activity.dtypes"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "StatementMeta(SparkPool01, 2, 17, Finished, Available)"
            ],
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "SparkPool01",
              "session_id": 2,
              "statement_id": 17,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-07-01T19:59:40.8070707Z",
              "session_start_time": null,
              "execution_start_time": "2021-07-01T19:59:40.9070179Z",
              "execution_finish_time": "2021-07-01T19:59:42.9859272Z"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('sourceName', 'string'), ('sourceVersion', 'string'), ('device', 'string'), ('type', 'string'), ('unit', 'string'), ('creationDate', 'string'), ('startDate', 'string'), ('endDate', 'string'), ('value', 'string')]"
          ]
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": true
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "source": [
        "# functions to convert UTC to EST time zone and extract date/time elements\r\n",
        "convert_tz = lambda x: x.to_pydatetime()\r\n",
        "get_year = lambda x: convert_tz(x).year\r\n",
        "get_month = lambda x: '{}-{:02}'.format(convert_tz(x).year, convert_tz(x).month) #inefficient\r\n",
        "get_date = lambda x: '{}-{:02}-{:02}'.format(convert_tz(x).year, convert_tz(x).month, convert_tz(x).day) #inefficient\r\n",
        "get_day = lambda x: convert_tz(x).day\r\n",
        "get_hour = lambda x: convert_tz(x).hour\r\n",
        "get_minute = lambda x: convert_tz(x).minute\r\n",
        "get_day_of_week = lambda x: convert_tz(x).weekday()\r\n",
        "\r\n"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "StatementMeta(SparkPool01, 2, 19, Finished, Available)"
            ],
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "SparkPool01",
              "session_id": 2,
              "statement_id": 19,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-07-01T20:00:03.8969037Z",
              "session_start_time": null,
              "execution_start_time": "2021-07-01T20:00:04.0220756Z",
              "execution_finish_time": "2021-07-01T20:00:06.0908686Z"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": true
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "source": [
        "from datetime import date, datetime, timedelta as td\r\n",
        "import pytz\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "# parse out date and time elements as EST time\r\n",
        "activity['startDate'] = pd.to_datetime(activity['startDate'])\r\n",
        "activity['year'] = activity['startDate'].map(get_year)\r\n",
        "activity['month'] = activity['startDate'].map(get_month)\r\n",
        "activity['date'] = activity['startDate'].map(get_date)\r\n",
        "activity['day'] = activity['startDate'].map(get_day)\r\n",
        "activity['hour'] = activity['startDate'].map(get_hour)\r\n",
        "activity['dow'] = activity['startDate'].map(get_day_of_week)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "StatementMeta(SparkPool01, 2, 22, Finished, Available)"
            ],
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "SparkPool01",
              "session_id": 2,
              "statement_id": 22,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-07-01T20:09:59.2005027Z",
              "session_start_time": null,
              "execution_start_time": "2021-07-01T20:09:59.3393839Z",
              "execution_finish_time": "2021-07-01T20:10:01.4023391Z"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Cannot convert column into bool: please use '&' for 'and', '|' for 'or', '~' for 'not' when building DataFrame boolean expressions.",
          "traceback": [
            "ValueError: Cannot convert column into bool: please use '&' for 'and', '|' for 'or', '~' for 'not' when building DataFrame boolean expressions.",
            "Traceback (most recent call last):\n",
            "  File \"/home/trusted-service-user/cluster-env/env/lib/python3.6/site-packages/pandas/util/_decorators.py\", line 208, in wrapper\n    return func(*args, **kwargs)\n",
            "  File \"/home/trusted-service-user/cluster-env/env/lib/python3.6/site-packages/pandas/core/tools/datetimes.py\", line 773, in to_datetime\n    elif isinstance(arg, ABCSeries):\n",
            "  File \"/home/trusted-service-user/cluster-env/env/lib/python3.6/site-packages/pandas/core/dtypes/generic.py\", line 9, in _check\n    return getattr(inst, attr, \"_typ\") in comp\n",
            "  File \"/opt/spark/python/lib/pyspark.zip/pyspark/sql/column.py\", line 690, in __nonzero__\n    raise ValueError(\"Cannot convert column into bool: please use '&' for 'and', '|' for 'or', \"\n",
            "ValueError: Cannot convert column into bool: please use '&' for 'and', '|' for 'or', '~' for 'not' when building DataFrame boolean expressions.\n"
          ]
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": true
      }
    }
  ]
}