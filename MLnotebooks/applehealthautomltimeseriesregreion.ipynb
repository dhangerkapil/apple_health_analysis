{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python"
    },
    "save_output": true,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import azureml.core\r\n",
        "\r\n",
        "from azureml.core import Experiment, Workspace, Dataset, Datastore\r\n",
        "from azureml.train.automl import AutoMLConfig\r\n",
        "from azureml.data.dataset_factory import TabularDatasetFactory"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "%%pyspark\r\n",
        "df = spark.read.load('file_in_datalake', format='csv'\r\n",
        "## If header exists uncomment line below\r\n",
        ", header=True\r\n",
        ")\r\n",
        "df.write.mode(\"overwrite\").saveAsTable(\"default.ActivitySummary\")"
      ],
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "python"
        },
        "collapsed": true
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "subscription_id = \"your_subscription_id\"\r\n",
        "resource_group = \"your_resource_group\"\r\n",
        "workspace_name = \"your_mlworkspace\"\r\n",
        "experiment_name = \"experimentname\"\r\n",
        "\r\n",
        "ws = Workspace(subscription_id = subscription_id, resource_group = resource_group, workspace_name = workspace_name)\r\n",
        "experiment = Experiment(ws, experiment_name)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "df = spark.sql(\"SELECT * FROM default.activitysummary\")\r\n",
        "\r\n",
        "datastore = Datastore.get_default(ws)\r\n",
        "dataset = TabularDatasetFactory.register_spark_dataframe(df, datastore, name = experiment_name + \"-dataset\")"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "automl_config = AutoMLConfig(spark_context = sc,\r\n",
        "                             task = \"regression\",\r\n",
        "                             training_data = dataset,\r\n",
        "                             label_column_name = \"activeEnergyBurned\",\r\n",
        "                             primary_metric = \"normalized_root_mean_squared_error\",\r\n",
        "                             experiment_timeout_hours = 3,\r\n",
        "                             max_concurrent_iterations = 2,\r\n",
        "                             enable_onnx_compatible_models = True)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "run = experiment.submit(automl_config)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "displayHTML(\"<a href={} target='_blank'>Your experiment in Azure Machine Learning portal: {}</a>\".format(run.get_portal_url(), run.id))"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "run.wait_for_completion()\r\n",
        "\r\n",
        "import onnxruntime\r\n",
        "import mlflow\r\n",
        "import mlflow.onnx\r\n",
        "\r\n",
        "from mlflow.models.signature import ModelSignature\r\n",
        "from mlflow.types import DataType\r\n",
        "from mlflow.types.schema import ColSpec, Schema\r\n",
        "\r\n",
        "# Get best model from automl run\r\n",
        "best_run, onnx_model = run.get_output(return_onnx_model=True)\r\n",
        "\r\n",
        "# Define utility functions to infer the schema of ONNX model\r\n",
        "def _infer_schema(data):\r\n",
        "    res = []\r\n",
        "    for _, col in enumerate(data):\r\n",
        "        t = col.type.replace(\"tensor(\", \"\").replace(\")\", \"\")\r\n",
        "        if t in [\"bool\"]:\r\n",
        "            dt = DataType.boolean\r\n",
        "        elif t in [\"int8\", \"uint8\", \"int16\", \"uint16\", \"int32\"]:\r\n",
        "            dt = DateType.integer\r\n",
        "        elif t in [\"uint32\", \"int64\"]:\r\n",
        "            dt = DataType.long\r\n",
        "        elif t in [\"float16\", \"bfloat16\", \"float\"]:\r\n",
        "            dt = DataType.float\r\n",
        "        elif t in [\"double\"]:\r\n",
        "            dt = DataType.double\r\n",
        "        elif t in [\"string\"]:\r\n",
        "            dt = DataType.string\r\n",
        "        else:\r\n",
        "            raise Exception(\"Unsupported type: \" + t)\r\n",
        "        res.append(ColSpec(type=dt, name=col.name))\r\n",
        "    return Schema(res)\r\n",
        "\r\n",
        "def _infer_signature(onnx_model):\r\n",
        "    onnx_model_bytes = onnx_model.SerializeToString()\r\n",
        "    onnx_runtime = onnxruntime.InferenceSession(onnx_model_bytes)\r\n",
        "    inputs = _infer_schema(onnx_runtime.get_inputs())\r\n",
        "    outputs = _infer_schema(onnx_runtime.get_outputs())\r\n",
        "    return ModelSignature(inputs, outputs)\r\n",
        "\r\n",
        "# Infer signature of ONNX model\r\n",
        "signature = _infer_signature(onnx_model)\r\n",
        "\r\n",
        "artifact_path = experiment_name + \"_artifact\"\r\n",
        "mlflow.set_tracking_uri(ws.get_mlflow_tracking_uri())\r\n",
        "mlflow.set_experiment(experiment_name)\r\n",
        "\r\n",
        "with mlflow.start_run() as run:\r\n",
        "    # Save the model to the outputs directory for capture\r\n",
        "    mlflow.onnx.log_model(onnx_model, artifact_path, signature=signature)\r\n",
        "\r\n",
        "    # Register the model to AML model registry\r\n",
        "    mlflow.register_model(\"runs:/\" + run.info.run_id + \"/\" + artifact_path, \"activitysummary-regression-Best\")"
      ],
      "outputs": [],
      "metadata": {}
    }
  ]
}